---
layout: single
title: "ë„¤ì´ë²„ ë‰´ìŠ¤ í¬ë¡¤ëŸ¬"
categories: Coding
tag: [Crawler, Naver news]
toc: true
toc_sticky: true
toc_label: ëª©ì°¨
author_profile: false
---

##  <img src="C:\Users\hjopy\OneDrive\ë°”íƒ• í™”ë©´\Jake\blog\blog\crackernote.github.io\assets\images\ê·¸ë¦¼1.png" alt="ê·¸ë¦¼1" style="zoom:6%;" /> ë„¤ì´ë²„ ë‰´ìŠ¤ í¬ë¡¤ëŸ¬

### ğŸ“œë„¤ì´ë²„ ë‰´ìŠ¤ í¬ë¡¤ë§

- ë‰´ìŠ¤ ê²€ìƒ‰ ê²°ê³¼ì—ì„œ ì œëª© ë° URL í¬ë¡¤ë§

  ```python
  import requests
  from bs4 import BeautifulSoup
  
  response = requests.get("https://search.naver.com/search.naver?sm=tab_hty.top&where=news&query=%EC%82%BC%EC%84%B1%EC%A0%84%EC%9E%90&oquery=%EC%B9%B4%EC%B9%B4%EC%98%A4%ED%8E%98%EC%9D%B4%EC%A6%9D%EA%B6%8C&tqi=it8Emlp0JXVssa5Kd0GssssstYR-349658")
  html = response.text
  
  soup = BeautifulSoup(html, 'html.parser')
  links = soup.select(".news_tit")
  
  for link in links:
      title = link.text
      url = link.attrs['href']
      print(title, url)
  ```
  
  
  

### ğŸ“œí¬ë¡¤ë§ ì½”ë“œì— ê²€ìƒ‰ì–´ ê¸°ëŠ¥ ì¶”ê°€

- ê²€ìƒ‰ì–´ì— ë”°ë¼ ë‹¤ë¥¸ ë‰´ìŠ¤ ê¸°ì‚¬ í¬ë¡¤ë§

  ```python
  import requests
  from bs4 import BeautifulSoup
  import pyautogui
  
  keyword = pyautogui.prompt("ê²€ìƒ‰ì–´ë¥¼ ì…ë ¥í•˜ì„¸ìš”>>>")
  response = requests.get(f"https://search.naver.com/search.naver?sm=tab_hty.top&where=news&query={keyword}")
  html = response.text
  
  soup = BeautifulSoup(html, 'html.parser')
  links = soup.select(".news_tit")
  
  for link in links:
      title = link.text
      url = link.attrs['href']
      print(title, url)
  
  ```

  

### ğŸ“œì—¬ëŸ¬ í˜ì´ì§€ í¬ë¡¤ë§í•˜ê¸°

- ë‰´ìŠ¤ ê¸°ì‚¬ ì—¬ëŸ¬ í˜ì´ì§€ í¬ë¡¤ë§í•˜ê¸°

  ```python
  import requests
  from bs4 import BeautifulSoup
  import pyautogui
  
  keyword = pyautogui.prompt("ê²€ìƒ‰ì–´ë¥¼ ì…ë ¥í•˜ì„¸ìš”")
  lastpage = pyautogui.prompt("ë§ˆì§€ë§‰ í˜ì´ì§€ë²ˆí˜¸ë¥¼ ì…ë ¥í•˜ì„¸ìš”")
  pageNum = 1
  
  for i in range(1, int(lastpage)*10, 10):
      print(f"{pageNum}í˜ì´ì§€ ì…ë‹ˆë‹¤.=========================")
      response = requests.get(f"https://search.naver.com/search.naver?sm=tab_hty.top&where=news&query={keyword}")
      html = response.text
      soup = BeautifulSoup(html, 'html.parser')
      links = soup.select(".news_tit")
      for link in links:
          title = link.text
          url = link.attrs['href']
          print(title, url)
      pageNum = pageNum + 1
  
  ```
